{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as iter\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, UpSampling2D\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE():\n",
    "    def __init__(self, optimizer, loss):\n",
    "        self.p_matrix = np.load(\"5x5matrix.npz\")[\"p_matrix\"]\n",
    "        self.q_matrix = np.load(\"5x5matrix.npz\")[\"q_matrix\"]\n",
    "        self.optimizer = optimizer\n",
    "        self.model = Sequential([\n",
    "            tf.keras.layers.Dense(25, activation = tf.nn.relu, input_dim = 16),\n",
    "            tf.keras.layers.Dense(25, activation = tf.nn.relu),\n",
    "            tf.keras.layers.Dense(25, activation = tf.nn.sigmoid)\n",
    "        ])\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                           loss = loss,\n",
    "                           metrics = ['accuracy'])\n",
    "    def fit(self, epochs, batch_size):\n",
    "        self.model.fit(self.q_matrix, self.p_matrix,\n",
    "                      epochs = epochs,\n",
    "                      batch_size = batch_size,\n",
    "                      validation_data = (self.q_matrix, self.p_matrix))\n",
    "    \n",
    "    def predict(self, test_img, threshold):\n",
    "        preds = self.model.predict(test_img).reshape(4,4)\n",
    "        preds_binary = preds.copy()\n",
    "        preds_binary[preds_binary < threshold] = 0\n",
    "        preds_binary[preds_binary >= threshold] = 1\n",
    "        ncols = 3\n",
    "        fig, axes = plt.subplots(nrows = 1, ncols = ncols, figsize = (14,14))\n",
    "        axes[0].imshow(test_img.reshape(3,3), cmap = plt.cm.binary)\n",
    "        axes[0].set_title(\"original image\")\n",
    "        axes[1].imshow(preds, cmap = plt.cm.binary)\n",
    "        axes[1].set_title(\"predicted image\")\n",
    "        axes[2].imshow(preds_binary, cmap = plt.cm.binary)\n",
    "        axes[2].set_title(\"predicted image with binalization\")\n",
    "    \n",
    "    def predict_RGB(self, test_img, threshold):\n",
    "        preds = np.empty((4,4,3), dtype='float32')\n",
    "        preds_binary = np.empty((4,4,3), dtype='float32')\n",
    "        for dim in range(test_img.shape[2]):\n",
    "            preds[ : , : , dim] = self.model.predict(test_img[ : , : , dim].reshape(1,9)).reshape(4,4)\n",
    "            preds_binary[ : , : , dim] = preds[ : , : , dim].copy()\n",
    "        preds_binary[preds_binary < threshold] = 0\n",
    "        preds_binary[preds_binary >= threshold] = 1\n",
    "        ncols = 3\n",
    "        fig, axes = plt.subplots(nrows = 1, ncols = ncols, figsize = (14,14))\n",
    "        axes[0].imshow(test_img, cmap = plt.cm.binary)\n",
    "        axes[0].set_title(\"original image\")\n",
    "        axes[1].imshow(preds, cmap = plt.cm.binary)\n",
    "        axes[1].set_title(\"predicted image\")\n",
    "        axes[2].imshow(preds_binary, cmap = plt.cm.binary)\n",
    "        axes[2].set_title(\"predicted image with binalization\")\n",
    "        \n",
    "    def SR(self, input_img, thresold):\n",
    "        # Preprocessing area\n",
    "        x, y, z = input_img.shape # dimention x and y\n",
    "        pad_list = [] # padding count x = 0, y = 1\n",
    "        for i in [x, y]:\n",
    "            if i % 3 == 0:\n",
    "                pad_list.append(0)\n",
    "            elif i % 3 == 1:\n",
    "                pad_list.append(2)\n",
    "            else:\n",
    "                pad_list.append(1)\n",
    "        \n",
    "        temp = np.zeros((x + pad_list[0], y + pad_list[1], 3), dtype='float32') # new temporary array replaced with input_img\n",
    "        temp[ 0 : x, 0 : y , 0 : z] = input_img\n",
    "        input_img = temp\n",
    "        m,n = int(input_img.shape[0] / 3), int(input_img.shape[1] / 3)\n",
    "        output_img = np.empty((4 * m , 4 * n, 3), dtype='float32')\n",
    "        print(pad_list[0], pad_list[1])\n",
    "        \n",
    "        # SR area\n",
    "        for dim in [0,1,2]:\n",
    "            for i, j in iter.product(range(n), range(m)):\n",
    "                partial_img = input_img.copy()[ 3 * j : 3 * ( j + 1 ), 3 * i : 3 * ( i + 1), dim] \n",
    "                if np.all(partial_img < 0.1):\n",
    "                    partial_img = np.zeros(16)\n",
    "                else:\n",
    "                    partial_img = self.model.predict( partial_img.reshape(1,9) )\n",
    "                output_img[4 * j : 4 * (j + 1), 4 * i : 4 * ( i + 1), dim] = partial_img.reshape(4,4)\n",
    "        \n",
    "        max_val = output_img.max()\n",
    "        output_img /= max_val\n",
    "        output_img_binalized = output_img.copy()\n",
    "        output_img_binalized[output_img_binalized >= thresold] = 1\n",
    "        output_img_binalized[output_img_binalized < thresold] = 0\n",
    "\n",
    "        fig, axes = plt.subplots(1,3, figsize = (16,16))\n",
    "        axes[0].imshow(input_img, cmap = plt.cm.binary)\n",
    "        axes[0].set_title(\"input image\")\n",
    "        axes[1].imshow(output_img, cmap = plt.cm.binary)\n",
    "        axes[1].set_title(\"output image\")\n",
    "        axes[2].imshow(output_img_binalized, cmap = plt.cm.binary)\n",
    "        axes[2].set_title(\"output image with biinalization\")\n",
    "        \n",
    "        return output_img\n",
    "    \n",
    "    def SR2(self, file_path, mean = 0 , sd = 0.2):\n",
    "        # Resizing area\n",
    "        input_img = Image.open(file_path)\n",
    "        img_width, img_height = input_img.size\n",
    "        \n",
    "        ratio = 3 / 4\n",
    "        resized_width =  int(input_img.size[0] * ratio)\n",
    "        resized_height = int(input_img.size[1] * ratio)\n",
    "        resized_img = input_img.resize((resized_width, resized_height))\n",
    "        resized_img = np.array(resized_img, \"f\") / 255\n",
    "        resized_img = resized_img + np.random.normal(mean, sd, (resized_height, resized_width, 3))\n",
    "        input_img = np.array(input_img, 'f') / 255\n",
    "        \n",
    "        # Preprocessing area\n",
    "        x, y, z = resized_img.shape # dimention x and y\n",
    "        pad_list = [] # padding count x = 0, y = 1\n",
    "        for i in [x, y]:\n",
    "            if i % 3 == 0:\n",
    "                pad_list.append(0)\n",
    "            elif i % 3 == 1:\n",
    "                pad_list.append(2)\n",
    "            else:\n",
    "                pad_list.append(1)\n",
    "        \n",
    "        temp = np.zeros((x + pad_list[0], y + pad_list[1], 3), dtype='float32') # new temporary array replaced with input_img\n",
    "        temp[ 0 : x, 0 : y , 0 : z] = resized_img\n",
    "        resized_img = temp\n",
    "        m,n = int(resized_img.shape[0] / 3), int(resized_img.shape[1] / 3)\n",
    "        output_img = np.empty((4 * m , 4 * n, 3), dtype='float32')\n",
    "        print(pad_list[0], pad_list[1])\n",
    "        \n",
    "        # SR area\n",
    "        for dim in [0,1,2]:\n",
    "            for i, j in iter.product(range(n), range(m)):\n",
    "                partial_img = resized_img.copy()[ 3 * j : 3 * ( j + 1 ), 3 * i : 3 * ( i + 1), dim] \n",
    "                if np.all(partial_img < 0.1):\n",
    "                    partial_img = np.zeros(16)\n",
    "                else:\n",
    "                    partial_img = self.model.predict( partial_img.reshape(1,9) )\n",
    "                output_img[4 * j : 4 * (j + 1), 4 * i : 4 * ( i + 1), dim] = partial_img.reshape(4,4)\n",
    "        \n",
    "        max_val = output_img.max()\n",
    "        output_img /= max_val\n",
    "\n",
    "        fig, axes = plt.subplots(1,3, figsize = (12,12))\n",
    "        axes[0].imshow(input_img, cmap = plt.cm.binary)\n",
    "        axes[0].set_title(\"input image\")\n",
    "        axes[1].imshow(resized_img, cmap = plt.cm.binary)\n",
    "        axes[1].set_title(\"resized image\")\n",
    "        axes[2].imshow(output_img, cmap = plt.cm.binary)\n",
    "        axes[2].set_title(\"output image\")\n",
    "        \n",
    "        return output_img\n",
    "    \n",
    "    def SR3(self, test_img):\n",
    "        preds = self.model.predict(test_img).reshape(4,4)\n",
    "        preds_binary = preds.copy()\n",
    "        preds_binary[preds_binary < threshold] = 0\n",
    "        preds_binary[preds_binary >= threshold] = 1\n",
    "        print(preds, preds_binary)\n",
    "        \n",
    "        ncols = 5\n",
    "        fig, axes = plt.subplots(nrows = 1, ncols = ncols, figsize = (14,14))\n",
    "        bayes_image = np.empty(16)\n",
    "        index_when_given_q = np.all(self.q_matrix == test_img.reshape(9,), axis = 1)\n",
    "        p_given_q = self.p_matrix[index_when_given_q]\n",
    "        print(p_given_q)\n",
    "        for col in range(16):\n",
    "            is_one_counter = 0\n",
    "            target_list = [p_given_q[row][col] for row in range(p_given_q.shape[0])]\n",
    "            total_length = len(target_list)\n",
    "            for j in range(total_length):\n",
    "                if target_list[j] == 1:\n",
    "                    is_one_counter += 1\n",
    "                prob = is_one_counter / total_length\n",
    "                bayes_image[i] = prob\n",
    "        \n",
    "        axes[0].imshow(test_img.reshape(3,3), cmap = plt.cm.binary)\n",
    "        axes[0].set_title(\"original image\")\n",
    "        axes[1].imshow(preds, cmap = plt.cm.binary)\n",
    "        axes[1].set_title(\"predicted image\")\n",
    "        axes[2].imshow(preds_binary, cmap = plt.cm.binary)\n",
    "        axes[2].set_title(\"predicted image with binalization\")\n",
    "        axes[3].imshow(bayes_image.reshape(4,4), cmap = plt.cm.binary)\n",
    "        axes[3].set_title(\"p(P|Q) image based on bayes\")\n",
    "        bayes_image[ bayes_image < thresold ] = 0\n",
    "        bayes_image[ bayes_image >= thresold ] = 1\n",
    "        axes[4].imshow(bayes_image.reshape(4,4), cmap = plt.cm.binary)\n",
    "        axes[4].set_title(\"p(P|Q) image based on bayes with binalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AE(optimizer = tf.train.AdamOptimizer(learning_rate=5e-4) , loss = tf.keras.losses.binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 25)                425       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 25)                650       \n",
      "=================================================================\n",
      "Total params: 1,725\n",
      "Trainable params: 1,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33554432 samples, validate on 33554432 samples\n",
      "Epoch 1/5\n",
      "33554432/33554432 [==============================] - 438s 13us/step - loss: 0.2343 - acc: 0.8980 - val_loss: 0.2170 - val_acc: 0.9074\n",
      "Epoch 2/5\n",
      "33554432/33554432 [==============================] - 414s 12us/step - loss: 0.2170 - acc: 0.9074 - val_loss: 0.2170 - val_acc: 0.9074\n",
      "Epoch 3/5\n",
      "33548288/33554432 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9074"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-758c2212fb96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-69661e824d2c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                       validation_data = (self.q_matrix, self.p_matrix))\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 verbose=0)\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m               \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.fit(epochs = 5, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
